{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing ORBIS's dataset for matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General information\n",
    "The objective of this code is divided in these main objectives: \n",
    "\n",
    "- Recode the geographical zones. \n",
    "- Cleaning company names. \n",
    "- Reshape the dataset such that each observation corresponds to a single possible name of a firm in one of its possible locations. \n",
    "- Remove 'stopwords'. \n",
    "- Save the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input files\n",
    "1. **orbis:** `'/scratch/public/jpvasquez/MNCs_informality/Raw_data/ORBIS/Orbis_for_Denue_merge.dta'` This file has geographical location variables, number of workers, ORBIS and DENUE's firm keys, generic firm names and business names (razon social). \n",
    "2. **orbis_geo_corrected:** `'/scratch/public/jpvasquez/MNCs_informality/Intermediate_data/data/orbis_municipalities_corrected.csv'` This file contains the geographical zones of firms with their proper coding, which procedure is documented in `'/scratch/public/jpvasquez/MNCs_informality/Intermediate_data/data/cleaning_datasets_orbis_denue.md'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis_file = '/scratch/public/jpvasquez/MNCs_informality/Raw_data/ORBIS/Orbis_for_Denue_merge.dta'\n",
    "orbis_geo_corrected_file = '/scratch/public/jpvasquez/MNCs_informality/Intermediate_data/data/orbis_municipalities_corrected.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output files\n",
    "1. **orbis_final:** `'/scratch/public/jpvasquez/MNCs_informality/Intermediate_data/output/orbis_final.csv'` This file contains a data set where each row represents a firm with one of their names associated, also, entity, municipality and ORBIS's BVDID number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis_final = '/scratch/public/jpvasquez/MNCs_informality/Intermediate_data/output/orbis_final.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "These are the needed packages to run this code. In case, the machine you're running this in doesn't have any of these packages, run this code: \n",
    "\n",
    "`!pip install package_name`\n",
    "\n",
    "**Pandas** is the package which handles importing, wrangling, cleaning and doing everything with the data. \n",
    "\n",
    "**Numpy** is needed in order to declare missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis = pd.read_stata(orbis_file)\n",
    "orbis_geo_corrected = pd.read_csv(orbis_geo_corrected_file, sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORBIS Geographical Zones Corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis_geo_corrected = orbis_geo_corrected.rename(columns = {'d_estado': 'entidad', # actual name: new name\n",
    "                                                            'd_mnpio': 'municipio', \n",
    "                                                            'd_cp': 'cp'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORBIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing company names for matching\n",
    "For each observation, we'll clean certain variables. First, remove accents or non-english characters. Second, replace caps for lower characters in strings. Third, remove multiple spaces. Fourth, replace space with \\_. Fifth, remove all non whitespace separators and letters. Finally, remove multiple spaces again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in orbis[['companyname1', 'companyname2', 'companyname3', \n",
    "                     'city1', 'region1', 'city2', \n",
    "                     'region2', 'city3', 'region3']]:\n",
    "    orbis[column] = (orbis[column].str.normalize('NFKD') # Removing\n",
    "                     .str.encode('ascii', errors='ignore') # the \n",
    "                     .str.decode('utf-8') # accents\n",
    "                     .str.lower() # replace caps\n",
    "                     .str.strip()) # remove multiple spaces\n",
    "    \n",
    "for column in orbis[['city1', 'region1', 'city2', 'region2', 'city3', 'region3']]:\n",
    "    orbis[column] = orbis[column].str.replace(\" \", \"_\") # replace space with _\n",
    "    \n",
    "for column in orbis[['companyname1', 'companyname2', 'companyname3']]:\n",
    "    orbis[column] = (orbis[column].str.replace('[^\\w\\s]','') # remove non whitespace separators and letters\n",
    "                     .str.strip()) # remove multiple spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping the data\n",
    "Note that we've got to do two reshapes: \n",
    "\n",
    "1. In the first one, we make each observation a single location for every BVDID number. \n",
    "2. In the second one, we get all the possible combinations of a firm name, their respective location and their BVDID number. \n",
    "\n",
    "This is important because in this data set there's no difference in BVDID number for a firm with two or three locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First reshape: Geographical zones\n",
    "For every tuple consisting of the trio of geographical characteristics (region, city and postcode), we use them to reshape the dataset with respect to the `bvdidnumber`. Also, the index is reset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis = (pd.wide_to_long(orbis, \n",
    "                         stubnames = ['postcode', 'city', 'region'], \n",
    "                         i = 'bvdidnumber', j = 'n')\n",
    "         .reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the null values generated\n",
    "First, for every `bvdidnumber`, we always keep the first possible location (which can be missing) and we keep the second and/or third possible location if the `entidad` or `municipio` is registered. Then, we append one to another and replace the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis1 = orbis[orbis['n'] == 1] # first possible location\n",
    "orbis2 = orbis[(orbis['n'] != 1) & (orbis['city'] != '') \n",
    "               & (orbis['region'] != '')] # second or third possible locations\n",
    "\n",
    "orbis = orbis1.append(orbis2).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an ID for the second reshape\n",
    "Now that we've got for each observation a single location, we don't exactly know which name is associated to what location. So, we can't assume any of them and have to consider all the possible combinations. \n",
    "\n",
    "Note that we need an unique identifier to do the reshape. In order to get an unique ID, we combine the `bvdidnumber` with `n`, which was generated by the first reshape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis['id'] = orbis['bvdidnumber'] + \"_\" + orbis['n'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop `n` to create a different one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis = orbis.drop(columns = 'n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second reshape: Possible company names\n",
    "Using `companyname` and the corresponding index, we reshape it again considering all the possible combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis = pd.wide_to_long(orbis, stubnames='companyname', \n",
    "                        i='id', j='n').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop observations without a company name\n",
    "Also, reset the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis = (orbis[orbis['companyname'] != '']\n",
    "         .reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create missing values\n",
    "We create missing values if there's spaces or a null string for every variable, we use `regex` option to capture every spacing size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis = orbis.replace(r'^\\s*$', np.NaN, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords\n",
    "There are multiple words that don't add more information or quality to our matching algorithms. We can assure this because all the firms have the same location: México, and we don't care about the company's structure in name similarity. Also, by looking manually in the data set, we detected common words that could qualify as stopwords and made a list with them. Then, for each possible firm name, we create a vector without the stopwords listed and joined them with spaces again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = ['de', 'a', 's', 'l', \n",
    "                'r', 'sade', 'v', 'c', \n",
    "                'b', 'sa', 'cv', 'sab', \n",
    "                'mexicana', 'mexicano', 'limitada', 'rl', \n",
    "                'mexico', 'latinoamerica', 'srl', 'mejico', \n",
    "                'via', 'its', 'funds', 'y', \n",
    "                'sapi', 'enr', 'sofom', 'mxico', \n",
    "                'latin', 'america', 'internacional', 'mexicanos', \n",
    "                'mexicanas', 'mex', 'er']\n",
    "orbis['companyname'] = (orbis['companyname']\n",
    "                        .apply(lambda x: ' '.join([word for word in x.split() \n",
    "                                                   if word not in (remove_words)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recode geographical zones\n",
    "Using merge on `region`, `city` and `postcode`, the correct names of the geographical zones are associated according to the assigned codes `entidad`, `municipalidad` and `cp` in `orbis_geo_corrected`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orbis = orbis.merge(orbis_geo_corrected, how = 'left', \n",
    "                    left_on = ['region', 'city', 'postcode'], \n",
    "                    right_on = ['region', 'city', 'postcode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data to save it\n",
    "First, we drop the unnecessary variables. Then, we drop the duplicates if there are repeated company names. Finally, we reset the index, notice that there are many of them after remove punctuation, accents and multiple spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis = (orbis.drop(columns = ['id', 'n', 'city', \n",
    "                               'region', 'postcode', 'cp'])\n",
    "         .drop_duplicates(ignore_index = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataset\n",
    "We save the data set to a Comma Separated Values file and we order the columns in our preferred order by naming them one by one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbis.to_csv(orbis_final, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
